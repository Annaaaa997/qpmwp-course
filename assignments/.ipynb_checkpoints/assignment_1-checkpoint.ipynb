{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Deadline: 19.03.2025, 12:00 CET\n",
    "\n",
    "<Add your name, student-id and emal address>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import timeit # To compute runtimes\n",
    "from typing import Optional\n",
    "\n",
    "# Import third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import local modules\n",
    "project_root = os.path.dirname(os.path.dirname(os.getcwd()))   # Change this path if needed\n",
    "src_path = os.path.join(project_root, 'qpmwp-course\\\\src')\n",
    "sys.path.append(project_root)\n",
    "sys.path.append(src_path)\n",
    "from estimation.covariance import Covariance\n",
    "from estimation.expected_return import ExpectedReturn\n",
    "from optimization.constraints import Constraints\n",
    "from optimization.optimization import Optimization, Objective\n",
    "from optimization.optimization_data import OptimizationData\n",
    "from optimization.quadratic_program import QuadraticProgram, USABLE_SOLVERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Solver Horse Race\n",
    "\n",
    "### 1.a)\n",
    "(3 points)\n",
    "\n",
    "Generate a Multivariate-Normal random dataset of dimension TxN, T=1000, N=100, and compute a vector of expected returns, q, and a covariance matrix, P, using classes ExpectedReturn and Covariance respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the dimensions\n",
    "T = 1000  # Number of time periods\n",
    "N = 100   # Number of assets\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a random mean vector\n",
    "mean = np.random.uniform(-0.01, 0.01, N)\n",
    "\n",
    "# Generate a random covariance matrix (positive semi-definite)\n",
    "cov = np.random.uniform(0.0001, 0.001, (N, N))\n",
    "cov = np.dot(cov, cov.T)  # Symmetric positive semi-definite matrix\n",
    "cov += 1e-4 * np.eye(N)  # Ensure positive definiteness\n",
    "\n",
    "# Generate the Multivariate-Normal random dataset\n",
    "data = np.random.multivariate_normal(mean, cov, size=T)\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(data, columns=[f'Asset_{i+1}' for i in range(N)])\n",
    "\n",
    "# Create instances of ExpectedReturn and Covariance\n",
    "expected_return_estimator = ExpectedReturn()\n",
    "covariance_estimator = Covariance()\n",
    "\n",
    "# Compute the vector of expected returns (mean returns)\n",
    "q = expected_return_estimator.estimate(X=df, inplace=False)\n",
    "\n",
    "# Compute the covariance matrix\n",
    "P = covariance_estimator.estimate(X=df, inplace=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Vector of expected returns (q):\")\n",
    "print(q)\n",
    "\n",
    "print(\"\\nCovariance matrix (P):\")\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b)\n",
    "(3 points)\n",
    "\n",
    "Instantiate a constraints object by injecting column names of the data created in 1.a) as ids and add:\n",
    "- a budget constaint (i.e., asset weights have to sum to one)\n",
    "- lower bounds of 0.0 for all assets\n",
    "- upper bounds of 0.2 for all assets\n",
    "- group contraints such that the sum of the weights of the first 30 assets is <= 0.3, the sum of assets 31 to 60 is <= 0.4 and the sum of assets 61 to 100 is <= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optimization.constraints.Constraints at 0x1663129c9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Constraints class\n",
    "constraints = Constraints(ids = df.columns.tolist())\n",
    "\n",
    "# Add budget constraint\n",
    "constraints.add_budget()\n",
    "\n",
    "# Add box constraints \n",
    "constraints.add_box(lower=0, upper=0.2)\n",
    "\n",
    "# Add linear constraints\n",
    "# Group 1: Sum of weights of the first 30 assets <= 0.3\n",
    "G1 = pd.Series([1] * 30 + [0] * 70, index=df.columns)\n",
    "constraints.add_linear(g_values=G1, sense='<=', rhs=0.3, name='Group1')\n",
    "\n",
    "# Group 2: Sum of weights of assets 31 to 60 <= 0.4\n",
    "G2 = pd.Series([0] * 30 + [1] * 30 + [0] * 40, index=df.columns)\n",
    "constraints.add_linear(g_values=G2, sense='<=', rhs=0.4, name='Group2')\n",
    "\n",
    "# Group 3: Sum of weights of assets 61 to 100 <= 0.5\n",
    "G3 = pd.Series([0] * 60 + [1] * 40, index=df.columns)\n",
    "constraints.add_linear(g_values=G3, sense='<=', rhs=0.5, name='Group3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) \n",
    "(4 points)\n",
    "\n",
    "Solve a Mean-Variance optimization problem (using coefficients P and q in the objective function) which satisfies the above defined constraints.\n",
    "Repeat the task for all open-source solvers in qpsolvers and compare the results in terms of:\n",
    "\n",
    "- runtime\n",
    "- accuracy: value of the primal problem.\n",
    "- reliability: are all constarints fulfilled? Extract primal resisduals, dual residuals and duality gap.\n",
    "\n",
    "Generate a DataFrame with the solvers as column names and the following row index: 'solution_found': bool, 'objective': float, 'primal_residual': float, 'dual_residual': float, 'duality_gap': float, 'runtime': float.\n",
    "\n",
    "Put NA's for solvers that failed for some reason (e.g., unable to install the package or solvers throws an error during execution). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract constraints in the format required by the solver\n",
    "GhAb = constraints.to_GhAb()\n",
    "\n",
    "# Get the list of solvers\n",
    "solvers = list(USABLE_SOLVERS)\n",
    "\n",
    "# Initialize results DataFrame\n",
    "results = pd.DataFrame(index=['solution_found', 'objective', 'primal_residual', 'dual_residual', 'duality_gap', 'runtime'], \n",
    "                        columns=solvers)\n",
    "\n",
    "# Variable to store portfolio weights from the first successful solver\n",
    "previous_weights = None  \n",
    "\n",
    "for solver in solvers:\n",
    "    try:\n",
    "        start_time = timeit.default_timer()\n",
    "        \n",
    "        # Instantiate the Quadratic Program\n",
    "        qp = QuadraticProgram(\n",
    "            P=P.to_numpy(),\n",
    "            q=q.to_numpy() * -1,\n",
    "            G=GhAb['G'],\n",
    "            h=GhAb['h'],\n",
    "            A=GhAb['A'],\n",
    "            b=GhAb['b'],\n",
    "            lb=constraints.box['lower'].to_numpy(),\n",
    "            ub=constraints.box['upper'].to_numpy(),\n",
    "            solver=solver,\n",
    "        )\n",
    "\n",
    "        # Solve the optimization problem\n",
    "        qp.solve()\n",
    "\n",
    "        # Ensure the solution exists before accessing attributes\n",
    "        solution = qp.results.get('solution', None)\n",
    "\n",
    "        end_time = timeit.default_timer()\n",
    "\n",
    "        if solution is not None:\n",
    "            results.loc[:, solver] = [\n",
    "                solution.found, \n",
    "                qp.objective_value(),\n",
    "                solution.primal_residual() if callable(solution.primal_residual) else np.nan,\n",
    "                solution.dual_residual() if callable(solution.dual_residual) else np.nan,\n",
    "                solution.duality_gap()[0] if isinstance(solution.duality_gap(), list) else solution.duality_gap(),\n",
    "                end_time - start_time\n",
    "            ]\n",
    "            \n",
    "            # Store portfolio weights from the first successful solver\n",
    "            if previous_weights is None:\n",
    "                previous_weights = solution.x  # Store weights\n",
    "            \n",
    "    except Exception as e:\n",
    "        # If solver fails, store NaNs\n",
    "        results.loc[:, solver] = [False, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "        print(f\"Solver {solver} failed: {e}\")\n",
    "\n",
    "# Convert previous_weights to NumPy array for consistency\n",
    "if previous_weights is not None:\n",
    "    previous_weights = np.array(previous_weights)\n",
    "else:\n",
    "    print(\"Warning: No valid solution found for previous_weights.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "print(results)\n",
    "\n",
    "# Transpose results to ensure correct structure\n",
    "df_results = results.T.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Improved Plotting Function\n",
    "def plot_bar_chart(metric_name, color, ylabel, title):\n",
    "    if metric_name not in df_results.columns:\n",
    "        print(f\"Skipping {metric_name}: Not found in DataFrame\")\n",
    "        return\n",
    "    \n",
    "    # Convert list-like values to scalars\n",
    "    valid_data = df_results[metric_name].dropna().apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) == 1 else x)\n",
    "\n",
    "    if valid_data.empty:\n",
    "        print(f\"Skipping {metric_name}: No valid data to plot\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(valid_data.index, valid_data, color=color, alpha=0.7)\n",
    "\n",
    "    if valid_data.max() < 0:\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.xlabel(\"Solvers\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Generate bar charts for each metric\n",
    "for metric, color in zip([\"objective\", \"primal_residual\", \"dual_residual\", \"duality_gap\", \"runtime\"], \n",
    "                          [\"blue\", \"purple\", \"orange\", \"green\", \"red\"]):\n",
    "    plot_bar_chart(metric, color, metric.replace(\"_\", \" \").title(), f\"{metric.replace('_', ' ').title()} Comparison Across Solvers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analytical Solution to Minimum-Variance Problem\n",
    "\n",
    "(5 points)\n",
    "\n",
    "- Create a `MinVariance` class that follows the structure of the `MeanVariance` class.\n",
    "- Implement the `solve` method in `MinVariance` such that if `solver_name = 'analytical'`, the analytical solution is computed and stored within the object (if such a solution exists). If not, call the `solve` method from the parent class.\n",
    "- Create a `Constraints` object by injecting the same ids as in part 1.b) and add a budget constraint.\n",
    "- Instantiate a `MinVariance` object by setting `solver_name = 'analytical'` and passing instances of `Constraints` and `Covariance` as arguments.\n",
    "- Create an `OptimizationData` object that contains an element `return_series`, which consists of the synthetic data generated in part 1.a).\n",
    "- Solve the optimization problem using the created `MinVariance` object and compare the results to those obtained in part 1.c).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MinVariance Class\n",
    "class MinVariance(Optimization):\n",
    "\n",
    "    def __init__(self, constraints: Constraints, covariance: Optional[Covariance] = None, solver_name=\"analytical\", **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize MinVariance optimization.\n",
    "        \"\"\"\n",
    "        super().__init__(constraints=constraints, solver_name=solver_name, **kwargs)\n",
    "        self.covariance = covariance if covariance is not None else Covariance()\n",
    "        self.solver_name = solver_name  \n",
    "\n",
    "    def set_objective(self, optimization_data: OptimizationData) -> None:\n",
    "        \"\"\"\n",
    "        Set the objective function for minimum-variance optimization.\n",
    "        \"\"\"\n",
    "        # Compute covariance matrix\n",
    "        self.P = self.covariance.estimate(optimization_data.return_series.dropna())  # Ensure no missing values\n",
    "        \n",
    "        if self.P is None:\n",
    "            print(\"Covariance matrix computation failed, using manual computation...\")\n",
    "            self.P = np.cov(optimization_data.return_series.dropna(), rowvar=False)\n",
    "\n",
    "        if self.P is None or not isinstance(self.P, np.ndarray):\n",
    "            raise ValueError(\"Covariance matrix computation failed. Ensure `estimate()` is working correctly.\")\n",
    "\n",
    "        self.q = np.zeros(self.P.shape[0])  # No return maximization, only variance minimization\n",
    "\n",
    "    def solve(self) -> None:\n",
    "        \"\"\"\n",
    "        Solve the optimization problem. If solver_name='analytical', use analytical solution.\n",
    "        Otherwise, fall back to numerical optimization.\n",
    "        \"\"\"\n",
    "        if self.solver_name == 'analytical':  \n",
    "            try:\n",
    "                inv_P = np.linalg.pinv(self.P)  # Use pseudo-inverse to avoid singular matrix issues\n",
    "                ones = np.ones(len(self.q))\n",
    "                self.solution = np.dot(inv_P, ones) / np.dot(ones, np.dot(inv_P, ones))\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(\"Analytical solution not possible, falling back to numerical optimization.\")\n",
    "                return super().solve()\n",
    "        else:\n",
    "            return super().solve()\n",
    "\n",
    "\n",
    "# Create Constraints Object with Budget Constraint\n",
    "portfolio_constraints = Constraints(ids=df.columns.tolist())\n",
    "portfolio_constraints.add_budget(rhs=1.0, sense='=')\n",
    "\n",
    "# Instantiate MinVariance Object\n",
    "min_var_optimizer = MinVariance(constraints=portfolio_constraints, covariance=Covariance(), solver_name='analytical')\n",
    "\n",
    "# Prepare Optimization Data\n",
    "opt_data = OptimizationData(return_series=df.dropna(axis=0))  # Drop NaNs only along rows, keeping all assets\n",
    "\n",
    "# Solve the Optimization Problem\n",
    "min_var_optimizer.set_objective(opt_data)\n",
    "min_var_optimizer.solve()\n",
    "\n",
    "# Print Optimized Portfolio Weights\n",
    "print(\"\\nOptimized Portfolio Weights:\")\n",
    "print(min_var_optimizer.solution)\n",
    "\n",
    "# Compare Results with Part 1.c\n",
    "if min_var_optimizer.solution.shape == previous_weights.shape:\n",
    "    print(\"\\nComparison with Part 1.c Results:\")\n",
    "    print(\"Absolute Difference in Weights:\", np.abs(min_var_optimizer.solution - previous_weights))\n",
    "else:\n",
    "    print(\"Error: Shape mismatch. Ensure weight vectors match in size.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
